{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### Contents:\n",
    "- [Imports, reading in data, initial examination](#Initial-Steps)\n",
    "- [Taking care of Null values](#Null-Cleaning)\n",
    "- [Ensuring correct dataypes](#Datatypes)\n",
    "- [Renaming Columns](#Make-the-columns-more-descriptive)\n",
    "- [One hot encoding](#One-hot-encoding)\n",
    "- [Save the clean data](#Save-the-cleaned-data)\n",
    "- [Data dictionaries](#Data-dictionary-creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>138500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street Alley  \\\n",
       "0  109  533352170           60        RL           NaN     13517   Pave   NaN   \n",
       "1  544  531379050           60        RL          43.0     11492   Pave   NaN   \n",
       "2  153  535304180           20        RL          68.0      7922   Pave   NaN   \n",
       "3  318  916386060           60        RL          73.0      9802   Pave   NaN   \n",
       "4  255  906425045           50        RL          82.0     14235   Pave   NaN   \n",
       "\n",
       "  Lot Shape Land Contour  ... Screen Porch Pool Area Pool QC Fence  \\\n",
       "0       IR1          Lvl  ...            0         0     NaN   NaN   \n",
       "1       IR1          Lvl  ...            0         0     NaN   NaN   \n",
       "2       Reg          Lvl  ...            0         0     NaN   NaN   \n",
       "3       Reg          Lvl  ...            0         0     NaN   NaN   \n",
       "4       IR1          Lvl  ...            0         0     NaN   NaN   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold  Sale Type  SalePrice  \n",
       "0          NaN        0       3    2010        WD      130500  \n",
       "1          NaN        0       4    2009        WD      220000  \n",
       "2          NaN        0       1    2010        WD      109000  \n",
       "3          NaN        0       4    2010        WD      174000  \n",
       "4          NaN        0       3    2010        WD      138500  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in training data\n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "# look at first 5 rows of dataframe, see if any columns are obviously droppable (like 'Unnamed: 0')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2658</td>\n",
       "      <td>902301120</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2718</td>\n",
       "      <td>905108090</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9662</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2414</td>\n",
       "      <td>528218130</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>58.0</td>\n",
       "      <td>17104</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>902207150</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8520</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>535105100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0  2658  902301120          190        RM          69.0      9142   Pave   \n",
       "1  2718  905108090           90        RL           NaN      9662   Pave   \n",
       "2  2414  528218130           60        RL          58.0     17104   Pave   \n",
       "3  1989  902207150           30        RM          60.0      8520   Pave   \n",
       "4   625  535105100           20        RL           NaN      9500   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... 3Ssn Porch Screen Porch Pool Area Pool QC  \\\n",
       "0  Grvl       Reg          Lvl  ...          0            0         0     NaN   \n",
       "1   NaN       IR1          Lvl  ...          0            0         0     NaN   \n",
       "2   NaN       IR1          Lvl  ...          0            0         0     NaN   \n",
       "3   NaN       Reg          Lvl  ...          0            0         0     NaN   \n",
       "4   NaN       IR1          Lvl  ...          0          185         0     NaN   \n",
       "\n",
       "  Fence Misc Feature Misc Val Mo Sold  Yr Sold  Sale Type  \n",
       "0   NaN          NaN        0       4     2006        WD   \n",
       "1   NaN          NaN        0       8     2006        WD   \n",
       "2   NaN          NaN        0       9     2006        New  \n",
       "3   NaN          NaN        0       7     2007        WD   \n",
       "4   NaN          NaN        0       7     2009        WD   \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in test data\n",
    "test = pd.read_csv('../datasets/test.csv')\n",
    "\n",
    "# look at first 5 rows of dataframe, see if any columns are obviously droppable (like 'Unnamed: 0')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isn't that useful when you have 81 columns, but does list what I usually like to check for\n",
    "def initial_EDA(df):\n",
    "    # print out the data types to make sure the numeric columns truly are numeric\n",
    "    print(f'Do any columns contain null values?:\\n{df.isnull().sum()}')\n",
    "    # check the data types\n",
    "    print(f'\\nThe data types are:\\n{df.dtypes}')\n",
    "    # print the column names to make sure they are aptly named\n",
    "    print(f'\\nThe column names are:\\n{df.columns}')\n",
    "    # print the shape to see if it makes sense\n",
    "    print(f'\\nThe shape of your dataframe is:\\n{df.shape}')\n",
    "    # look at the descriptive stats for numerical columns in the data to get an initial feel for it\n",
    "    print(f'\\nDescriptive statistics:\\n{df.describe()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Checking for Null Values \n",
    "# and seeing what percentage of the dataset the nulls are, to decide if safe to drop that column or row\n",
    "\n",
    "def null_cleaning(df):\n",
    "    null_cols = []\n",
    "    problem_cols = []\n",
    "    \n",
    "    # looping through the columns\n",
    "    for i in range(df.shape[1]):\n",
    "        # counting the number of null vals in the column\n",
    "        num_nulls = df.isnull().sum()[i]\n",
    "        # if there are more than 0 null values, add the column to our list, and see what % of the data it is\n",
    "        if num_nulls != 0:\n",
    "            col_name = df.columns[i]\n",
    "            percent_of_data = round(num_nulls/df.shape[0], 3)\n",
    "            null_cols.append([col_name, num_nulls, percent_of_data])\n",
    "            # if this column is over 20% nulls, then mark it as a problem column\n",
    "            if percent_of_data >= 0.2:\n",
    "                problem_cols.append(col_name)\n",
    "                \n",
    "    # what happens if we drop the problem columns?\n",
    "    df_no_prob_cols = df.drop(columns = problem_cols)\n",
    "    prob_cols_percent = df_no_prob_cols.shape[1] / df.shape[1]\n",
    "    \n",
    "    #what happens is we drop the problem rows too?\n",
    "    df_no_nulls = df_no_prob_cols.dropna()\n",
    "    prob_rows_percent = df_no_nulls.shape[0]/df_no_prob_cols.shape[0]\n",
    "    \n",
    "    print(\"The problem columns are: \", problem_cols)\n",
    "    print(\"After dropping the problem columns, you are left with \", prob_cols_percent, \"% of your columns.\")\n",
    "    print(\"After dropping the problem columns, and then dropping all rows containing nulls,\\n you are left with \", \n",
    "          prob_rows_percent, \"% of your rows.\")\n",
    "    return null_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem columns are:  ['Alley', 'Fireplace Qu', 'Pool QC', 'Fence', 'Misc Feature']\n",
      "After dropping the problem columns, you are left with  0.9382716049382716 % of your columns.\n",
      "After dropping the problem columns, and then dropping all rows containing nulls,\n",
      " you are left with  0.7586543149683082 % of your rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Lot Frontage', 330, 0.161],\n",
       " ['Alley', 1911, 0.932],\n",
       " ['Mas Vnr Type', 22, 0.011],\n",
       " ['Mas Vnr Area', 22, 0.011],\n",
       " ['Bsmt Qual', 55, 0.027],\n",
       " ['Bsmt Cond', 55, 0.027],\n",
       " ['Bsmt Exposure', 58, 0.028],\n",
       " ['BsmtFin Type 1', 55, 0.027],\n",
       " ['BsmtFin SF 1', 1, 0.0],\n",
       " ['BsmtFin Type 2', 56, 0.027],\n",
       " ['BsmtFin SF 2', 1, 0.0],\n",
       " ['Bsmt Unf SF', 1, 0.0],\n",
       " ['Total Bsmt SF', 1, 0.0],\n",
       " ['Bsmt Full Bath', 2, 0.001],\n",
       " ['Bsmt Half Bath', 2, 0.001],\n",
       " ['Fireplace Qu', 1000, 0.488],\n",
       " ['Garage Type', 113, 0.055],\n",
       " ['Garage Yr Blt', 114, 0.056],\n",
       " ['Garage Finish', 114, 0.056],\n",
       " ['Garage Cars', 1, 0.0],\n",
       " ['Garage Area', 1, 0.0],\n",
       " ['Garage Qual', 114, 0.056],\n",
       " ['Garage Cond', 114, 0.056],\n",
       " ['Pool QC', 2042, 0.996],\n",
       " ['Fence', 1651, 0.805],\n",
       " ['Misc Feature', 1986, 0.968]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cleaning(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Since we would still have 93% of our columns, and then 75% of our rows after dropping nulls from the training dataset, it is safe to do so. However, it does seem like maybe the features we are dropping wouldn't be null for more expensive homes? Maybe should split this up later.\n",
    "    \n",
    "    \n",
    "    Alley (Nominal): Type of alley access to property\n",
    "\n",
    "       Grvl\tGravel\n",
    "       Pave\tPaved\n",
    "       NA \tNo alley access\n",
    "       \n",
    "    FireplaceQu (Ordinal): Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "       \n",
    "       \n",
    "     Pool QC (Ordinal): Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "       \n",
    "       \n",
    "     Fence (Ordinal): Fence quality\n",
    "\t\t\n",
    "       GdPrv\tGood Privacy\n",
    "       MnPrv\tMinimum Privacy\n",
    "       GdWo\tGood Wood\n",
    "       MnWw\tMinimum Wood/Wire\n",
    "       NA\tNo Fence\n",
    "       \n",
    "       \n",
    "\tMisc Feature (Nominal): Miscellaneous feature not covered in other categories\n",
    "\t\t\n",
    "       Elev\tElevator\n",
    "       Gar2\t2nd Garage (if not described in garage section)\n",
    "       Othr\tOther\n",
    "       Shed\tShed (over 100 SF)\n",
    "       TenC\tTennis Court\n",
    "       NA\tNone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the probelmatic columns from train\n",
    "train.drop(columns = ['Alley', 'Fireplace Qu', 'Pool QC', 'Fence', 'Misc Feature'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should also drop the same columns from test\n",
    "test.drop(columns = ['Alley', 'Fireplace Qu', 'Pool QC', 'Fence', 'Misc Feature'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the rows containing nulls now\n",
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556, 76)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape after all that dropping\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't drop rows from the test set willy nilly because we need to make 878 predictions\n",
    "\n",
    "# instead, replace the nulls with the mean for the numeric columns\n",
    "# and replace the nans in object columns with the empty string\n",
    "\n",
    "\n",
    "def replace_nans(df):\n",
    "    # replacing nans in numeric columns with the mean\n",
    "    numeric = df.select_dtypes(exclude=['object'])\n",
    "    for col in numeric.columns:\n",
    "        m = df[col].mean()\n",
    "        df[col].fillna(m, inplace = True)\n",
    "    \n",
    "    #replacing nans in object columns with the empty string\n",
    "    non_numeric = df.select_dtypes('object')\n",
    "    for col in non_numeric.columns:\n",
    "        df[col].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that it worked ok \n",
    "\n",
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping any other unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PID is just identification numbers and have no real measure of the quality of the house\n",
    "# they are numeric and could really exaggerate certain data points in a way we don't want them to\n",
    "# they may introduce irrelevant patterns\n",
    "\n",
    "train.drop(columns = ['PID'], inplace = True)\n",
    "test.drop(columns = ['PID'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                int64\n",
       "MS SubClass       int64\n",
       "MS Zoning        object\n",
       "Lot Frontage    float64\n",
       "Lot Area          int64\n",
       "                 ...   \n",
       "Misc Val          int64\n",
       "Mo Sold           int64\n",
       "Yr Sold           int64\n",
       "Sale Type        object\n",
       "SalePrice         int64\n",
       "Length: 75, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes   # too many columns for this to be useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function checks the datatype of every column that contains a number in a given row\n",
    "# prints the datatype of any entry that contains a number\n",
    "# can be used to check if numeric values are cast as objects\n",
    "# can also be used to see if entries with numbers are cast as float/int when actually you want them to be objects (like zipcodes)\n",
    "\n",
    "# n is the index of the row you want to check\n",
    "\n",
    "def dtype_check(df, n):\n",
    "    cols_to_examine = []\n",
    "    # looping through every entry in the row\n",
    "    for i in range(len(df.iloc[n])):\n",
    "        col_name = df.columns[i]\n",
    "        # looking at the entry as a string\n",
    "        entry = str(df.iloc[n][i])\n",
    "        # seeing if the entry contains any numbers\n",
    "        for letter in entry:\n",
    "            if letter in '0123456789':\n",
    "                # if there is a number in the entry, what is the datatype of that column\n",
    "                d_type = df.dtypes[i]\n",
    "                cols_to_examine.append([col_name, d_type, entry])\n",
    "                break   #so that it only does it once, only care if there is at least one number\n",
    "    return cols_to_examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Id', dtype('int64'), '318'],\n",
       " ['MS SubClass', dtype('int64'), '60'],\n",
       " ['Lot Frontage', dtype('float64'), '73.0'],\n",
       " ['Lot Area', dtype('int64'), '9802'],\n",
       " ['Bldg Type', dtype('O'), '1Fam'],\n",
       " ['House Style', dtype('O'), '2Story'],\n",
       " ['Overall Qual', dtype('int64'), '5'],\n",
       " ['Overall Cond', dtype('int64'), '5'],\n",
       " ['Year Built', dtype('int64'), '2006'],\n",
       " ['Year Remod/Add', dtype('int64'), '2007'],\n",
       " ['Mas Vnr Area', dtype('float64'), '0.0'],\n",
       " ['BsmtFin SF 1', dtype('float64'), '0.0'],\n",
       " ['BsmtFin SF 2', dtype('float64'), '0.0'],\n",
       " ['Bsmt Unf SF', dtype('float64'), '384.0'],\n",
       " ['Total Bsmt SF', dtype('float64'), '384.0'],\n",
       " ['1st Flr SF', dtype('int64'), '744'],\n",
       " ['2nd Flr SF', dtype('int64'), '700'],\n",
       " ['Low Qual Fin SF', dtype('int64'), '0'],\n",
       " ['Gr Liv Area', dtype('int64'), '1444'],\n",
       " ['Bsmt Full Bath', dtype('float64'), '0.0'],\n",
       " ['Bsmt Half Bath', dtype('float64'), '0.0'],\n",
       " ['Full Bath', dtype('int64'), '2'],\n",
       " ['Half Bath', dtype('int64'), '1'],\n",
       " ['Bedroom AbvGr', dtype('int64'), '3'],\n",
       " ['Kitchen AbvGr', dtype('int64'), '1'],\n",
       " ['TotRms AbvGrd', dtype('int64'), '7'],\n",
       " ['Fireplaces', dtype('int64'), '0'],\n",
       " ['Garage Yr Blt', dtype('float64'), '2007.0'],\n",
       " ['Garage Cars', dtype('float64'), '2.0'],\n",
       " ['Garage Area', dtype('float64'), '400.0'],\n",
       " ['Wood Deck SF', dtype('int64'), '100'],\n",
       " ['Open Porch SF', dtype('int64'), '0'],\n",
       " ['Enclosed Porch', dtype('int64'), '0'],\n",
       " ['3Ssn Porch', dtype('int64'), '0'],\n",
       " ['Screen Porch', dtype('int64'), '0'],\n",
       " ['Pool Area', dtype('int64'), '0'],\n",
       " ['Misc Val', dtype('int64'), '0'],\n",
       " ['Mo Sold', dtype('int64'), '4'],\n",
       " ['Yr Sold', dtype('int64'), '2010'],\n",
       " ['SalePrice', dtype('int64'), '174000']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it on a few random rows\n",
    "dtype_check(train,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>\n",
    "    Honestly the datatypes all look good to me! I feel like I got lucky? Seems to good to be true..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the columns more descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make names that look 'Like This' instead look 'like_this'. Only problem is that for names that look 'LikeThis' get changed to 'likethis'. But it's only a couple columns so if I really wanted to I could do that manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_names(df):\n",
    "    name_dict = {}\n",
    "    for name in df.columns:\n",
    "        new_name = name.lower().replace(' ','_')\n",
    "        name_dict[name] = new_name\n",
    "    return df.rename(columns = name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = change_names(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = change_names(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a sale price to the test data\n",
    "# sale price is nonzero for everything in train\n",
    "# so we'll keep track of what is train and what is test this way while we merge and unmerge\n",
    "\n",
    "sale_price = np.zeros_like(test['id'])\n",
    "test['saleprice'] = sale_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that train and test have the same number of columns\n",
    "test.shape[1] == train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data frames, just stack the rows\n",
    "train_and_test = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# make sure the merge went ok\n",
    "\n",
    "print(train_and_test.shape[1] == test.shape[1])\n",
    "print(train_and_test.shape[0] == test.shape[0]+train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will turn any object columns of a dataframe into dummies\n",
    "# it returns the dummied dataframe\n",
    "\n",
    "def dummy_the_objects(df):\n",
    "    non_numeric = df.select_dtypes('object')\n",
    "    return pd.get_dummies(df, columns = non_numeric.columns, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummying the merged dataframe \n",
    "\n",
    "train_and_test_d = dummy_the_objects(train_and_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2434, 246)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure we actually added more coumns\n",
    "\n",
    "train_and_test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to get just the dummied train data \n",
    "\n",
    "train_d = train_and_test_d[(train_and_test_d['saleprice']) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to get just the dummied test data\n",
    "\n",
    "test_d = train_and_test_d[(train_and_test_d['saleprice']) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556, 246)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# drop the sale price column of zeros from the test set \n",
    "\n",
    "test_d.drop(columns = 'saleprice', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 245)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have train and test with the same dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data dictionary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data with no dummies\n",
    "\n",
    "train.to_csv('../datasets/train_clean_no_dum.csv', index = False)\n",
    "test.to_csv('../datasets/test_clean_no_dum.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data with dummies \n",
    "\n",
    "train_d.to_csv('../datasets/train_clean_dum.csv', index = False)\n",
    "test_d.to_csv('../datasets/test_clean_dum.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Contents:\n",
    "- [Imports, reading in data, initial examination](#Initial-Steps)\n",
    "- [Taking care of Null values](#Null-Cleaning)\n",
    "- [Ensuring correct dataypes](#Datatypes)\n",
    "- [Renaming Columns](#Make-the-columns-more-descriptive)\n",
    "- [One hot encoding](#One-hot-encoding)\n",
    "- [Save the clean data](#Save-the-cleaned-data)\n",
    "- [Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
